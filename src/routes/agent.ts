import multer from 'multer';
import fs from 'fs';
import FormData from 'form-data';
import { Router } from 'express';
import { OpenAI } from 'openai';
import axios from 'axios';
import { functions } from '../contants/MCP_tools';
import { ChatCompletionMessageParam } from "openai/resources/chat";

const router = Router();
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const storage = multer.diskStorage({
  destination: function (req, file, cb) {
    const uploadPath = 'public/user_audio';
    fs.mkdirSync(uploadPath, { recursive: true });
    cb(null, uploadPath);
  },
  filename: function (req, file, cb) {
    const timestamp = Date.now();
    cb(null, `audio_${timestamp}.wav`);
  }
});
const upload = multer({ storage });

router.post('/audioTest', upload.single("file"), async (req, res) => {
    try {
        const file = req.file;
        if (!file) {
            res.status(400).json({ error: "æ²’æœ‰ä¸Šå‚³éŸ³æª”" });
            return;
        }

        console.log("âœ… æ”¶åˆ°éŸ³æª”:", file.originalname);
        
        const formData = new FormData();
        formData.append('file', fs.createReadStream(file.path), file.filename);

        try {
          const secondaryRes = await axios.post('http://127.0.0.1:8000/upload_user_audio', formData, {
            headers: formData.getHeaders(),
          });

          console.log('âœ… ç¬¬äºŒå¾Œç«¯å›æ‡‰:', secondaryRes.data);
        } catch (err) {
          console.error('âŒ å‚³é€åˆ°ç¬¬äºŒå¾Œç«¯å¤±æ•—:', err);
        }
        
        let finalResponse;
        let user_contest = "å­¸ç”ŸéŸ³æª”ç‚º```user_audio/" + file.filename + "```";
        let messages: ChatCompletionMessageParam[] = [
            { role: "system", content: "ä½ æ˜¯ä¸€å€‹è‹±æ–‡è€å¸«ï¼Œå¯ä»¥æ ¹æ“šéœ€æ±‚ä½¿ç”¨å¤šç¨®å·¥å…·ï¼ˆæ–‡æ³•æª¢æŸ¥ã€å¥å­æ¯”è¼ƒç­‰ç­‰ï¼‰å¹«åŠ©å­¸ç”Ÿã€‚" },
            { role: "user", content: user_contest }
          ];
        
          console.log(messages);
          
        while (true) {
          const response = await openai.chat.completions.create({
            model: "gpt-4",
            messages,
            functions,
            function_call: "auto"
          });
        
          const choice = response.choices[0];
          const message = choice.message;
        
          if (message.function_call) {
            const funcCall = message.function_call;
            const mcpPayload = {
              tool_calls: [
                {
                  id: `call-${Date.now()}`,
                  function: {
                    name: funcCall.name,
                    arguments: JSON.parse(funcCall.arguments || '{}')
                  }
                }
              ]
            };
        
            // ğŸ” å‘¼å« MCP æ‹¿çµæœ
            const mcpRes = await axios.post('http://localhost:8000/run', mcpPayload);
            const mcpResults = (mcpRes.data as { results: any[] }).results;
        
            // âœ… æŠŠ tool response ä¸Ÿå› GPT
            messages.push({ role: "assistant", function_call: funcCall });
            messages.push({
              role: "function",
              name: funcCall.name,
              content: JSON.stringify(mcpResults)
            });
            continue; // loop ç¹¼çºŒä¸‹ä¸€è¼ª
          }
        
          // ğŸ”š GPT å›å®Œæœ€çµ‚å›ç­”
          messages.push(message);
          // åŠ å…¥æœ€å¾Œè¦ç¸½çµçš„ä»»å‹™èªªæ˜
          messages.push({
              role: "user",
              content: "è«‹æ ¹æ“šä»¥ä¸Šæ‰€æœ‰å·¥å…·åˆ†æçµæœèˆ‡å°è©±ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡åšå‡ºæ•´ç†èˆ‡å»ºè­°ï¼Œä¸¦ç”¨ JSON æ ¼å¼è¼¸å‡ºã€‚"
          });
          
          // å‘¼å«æœ€å¾Œç¸½çµ
          finalResponse = await openai.chat.completions.create({
              model: "gpt-4",
              messages
          });
          break;
        }
        
        res.json({ reply: finalResponse.choices[0].message });
    } catch (error) {
        console.error("âŒ éŸ³æª”è™•ç†å¤±æ•—:", error);
        res.status(500).json({ error: "éŸ³æª”è™•ç†ç™¼ç”ŸéŒ¯èª¤" });
    }
});

router.post('/agent', async (req, res) => {
   try{
        const { prompt } = req.body;
        const response = await openai.chat.completions.create({
            model: "gpt-4o-mini",
            messages: [
                { role: "system", content: "ä½ æ˜¯ä¸€å€‹è‹±æ–‡æ•™å¸«ï¼Œå¯ä»¥ä½¿ç”¨funcstionsä¸­çš„å„ç¨®å·¥å…·ä¾†å”åŠ©å­¸ç”Ÿã€‚" },
                { role: "user", content: prompt }
            ],
            functions,
            temperature: 0.7,
        });
        res.status(200).json({
            reply: response.choices[0]
        });
        return;
   }catch(error){
       console.error("âŒ agent API è«‹æ±‚éŒ¯èª¤:", error);
       res.status(500).json({ error: "agent API ç™¼ç”ŸéŒ¯èª¤" });
   } 
});

router.get('/test', async (req, res) => {
    try{
        let finalResponse;
        let messages: ChatCompletionMessageParam[] = [
            { role: "system", content: "ä½ æ˜¯ä¸€å€‹è‹±æ–‡è€å¸«ï¼Œå¯ä»¥æ ¹æ“šéœ€æ±‚ä½¿ç”¨å¤šç¨®å·¥å…·ï¼ˆæ–‡æ³•æª¢æŸ¥ã€å¥å­æ¯”è¼ƒç­‰ç­‰ï¼‰å¹«åŠ©å­¸ç”Ÿã€‚" },
            { role: "user", content: "å­¸ç”ŸéŸ³æª”ç‚º```user_audio/MCP_introduction.wav```" }
          ];
          
          while (true) {
            const response = await openai.chat.completions.create({
              model: "gpt-4",
              messages,
              functions,
              function_call: "auto"
            });
          
            const choice = response.choices[0];
            const message = choice.message;
          
            if (message.function_call) {
              const funcCall = message.function_call;
              const mcpPayload = {
                tool_calls: [
                  {
                    id: `call-${Date.now()}`,
                    function: {
                      name: funcCall.name,
                      arguments: JSON.parse(funcCall.arguments || '{}')
                    }
                  }
                ]
              };
          
              // ğŸ” å‘¼å« MCP æ‹¿çµæœ
              const mcpRes = await axios.post('http://localhost:8000/run', mcpPayload);
              const mcpResults = (mcpRes.data as { results: any[] }).results;
          
              // âœ… æŠŠ tool response ä¸Ÿå› GPT
              messages.push({ role: "assistant", function_call: funcCall });
              messages.push({
                role: "function",
                name: funcCall.name,
                content: JSON.stringify(mcpResults)
              });
              continue; // loop ç¹¼çºŒä¸‹ä¸€è¼ª
            }
          
            // ğŸ”š GPT å›å®Œæœ€çµ‚å›ç­”
            messages.push(message);
            // åŠ å…¥æœ€å¾Œè¦ç¸½çµçš„ä»»å‹™èªªæ˜
            messages.push({
                role: "user",
                content: "è«‹æ ¹æ“šä»¥ä¸Šæ‰€æœ‰å·¥å…·åˆ†æçµæœèˆ‡å°è©±ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡åšå‡ºæ•´ç†èˆ‡å»ºè­°ï¼Œä¸¦ç”¨ JSON æ ¼å¼è¼¸å‡ºã€‚"
            });
            
            // å‘¼å«æœ€å¾Œç¸½çµ
            finalResponse = await openai.chat.completions.create({
                model: "gpt-4",
                messages
            });
            break;
          }
          
          res.json({ reply: finalResponse.choices[0].message });
          return;
    }catch(error){
        console.error("âŒ agent API æ¸¬è©¦éŒ¯èª¤:", error);
        res.status(500).json({ error: "agent API æ¸¬è©¦å¤±æ•—" });
    }
});

export default router;